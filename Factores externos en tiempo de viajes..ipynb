{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b415d12f-c4f4-41a8-bd49-99fee6074371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import spark.implicits._\n",
    "#import org.apache.spark.sql.functions._\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from scipy import stats as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bad4d31f-0a4b-41d6-bffb-3a1602d96a56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configurar el storage y las credenciales\n",
    "storage_account_name = \"etl2\"\n",
    "container_name = \"container1\"\n",
    "sas_token = \"sp=racwdlmeop&st=2024-10-04T19:56:30Z&se=2024-11-05T03:56:30Z&sv=2022-11-02&sr=c&sig=fInMPOlOvq8bb4UA0lIibhUNflYplQ3Q9mZK8BKyfKY%3D\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a4967ab-6922-4ae0-a035-df8bdaee8d34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montar el Data Lake Gen2\n",
    "dbutils.fs.updateMount(  source = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net\",\n",
    "  mount_point = f\"/mnt/{container_name}\",\n",
    "  extra_configs = {f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\": sas_token}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb491c6b-d7f1-47b1-9b2f-7588416359aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "  f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\",\n",
    "  f\"{sas_token}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a298f628-c093-45f5-928f-434fdc9f57e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/mnt/container1/cabs.csv', name='cabs.csv', size=31998, modificationTime=1728164694000),\n",
       " FileInfo(path='dbfs:/mnt/container1/datos.csv', name='datos.csv', size=28955, modificationTime=1728081187000),\n",
       " FileInfo(path='dbfs:/mnt/container1/neighborhoods.csv', name='neighborhoods.csv', size=1521, modificationTime=1728164694000),\n",
       " FileInfo(path='dbfs:/mnt/container1/new_retail_data.csv', name='new_retail_data.csv', size=84920745, modificationTime=1728071170000),\n",
       " FileInfo(path='dbfs:/mnt/container1/trips.csv', name='trips.csv', size=10817, modificationTime=1728164694000),\n",
       " FileInfo(path='dbfs:/mnt/container1/weather_records.csv', name='weather_records.csv', size=8187, modificationTime=1728164694000)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/container1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3410897-f6ea-4b79-89fd-47627f0c44a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Mundo!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hola Mundo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01ba222f-bc1b-46d0-a6b3-a15afbdd2255",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar el dataset desde el Data Lake Gen2\n",
    "cabs = spark.read.csv(\"/mnt/container1/cabs.csv\", header=True, inferSchema=True)\n",
    "trips = spark.read.csv(\"/mnt/container1/trips.csv\", header=True, inferSchema=True)\n",
    "neighborhoods = spark.read.csv(\"/mnt/container1/neighborhoods.csv\", header=True, inferSchema=True)\n",
    "weather_records = spark.read.csv(\"/mnt/container1/weather_records.csv\", header=True, inferSchema=True)\n",
    "datos = spark.read.csv(\"/mnt/container1/datos.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65c75ed-f5ed-46b9-913b-aa7f04fec7de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[Date and time: timestamp, Temperature: double, Description: string]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabs.cache()\n",
    "trips.cache()\n",
    "neighborhoods.cache()\n",
    "weather_records.cache()\n",
    "datos.cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca925a7b-6875-4ccd-a630-775f1bc9edaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cabs = cabs.dropDuplicates()\n",
    "trips = trips.dropDuplicates()\n",
    "neighborhoods = neighborhoods.dropDuplicates()\n",
    "weather_records = weather_records.dropDuplicates()\n",
    "datos = datos.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15a3df12-f4b6-43f0-8cf4-22497734008a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cabs.createOrReplaceTempView(\"cabs\")\n",
    "trips.createOrReplaceTempView(\"trips\")\n",
    "neighborhoods.createOrReplaceTempView(\"neighborhoods\")\n",
    "weather_records.createOrReplaceTempView(\"weather_records\")\n",
    "datos.createOrReplaceTempView(\"datos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4520af-f30b-4099-a281-399419970168",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro1 = spark.sql(\"\"\" \n",
    "        SELECT company_name, COUNT(trips.trip_id) AS trips_amount\n",
    "        FROM cabs INNER JOIN trips ON cabs.cab_id = trips.cab_id\n",
    "        WHERE DATE(start_ts) IN ('2017-11-15', '2017-11-16')\n",
    "        GROUP BY cabs.company_name\n",
    "        ORDER BY trips_amount DESC\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7037ea43-06ff-4961-a288-8d3180acb15e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------------+----------------+----------------+--------------+------------------+-------------------+\n|trip_id|cab_id|        start_ts|          end_ts|duration_seconds|distance_miles|pickup_location_id|dropoff_location_id|\n+-------+------+----------------+----------------+----------------+--------------+------------------+-------------------+\n|     19|  3953|03/11/2017 19:00|03/11/2017 19:00|             453|           1.3|                 0|                  0|\n|      3|  1768|03/11/2017 14:00|03/11/2017 15:00|             318|           0.9|                 0|                  0|\n|     14|  1943|01/11/2017 20:00|01/11/2017 20:00|             120|           0.5|                 0|                  0|\n|     10|  3981|28/11/2017 00:00|28/11/2017 00:00|             136|           0.8|                 0|                  0|\n|     15|   266|06/11/2017 11:00|06/11/2017 11:00|             180|           0.5|                 0|                  0|\n|      4|  4274|24/11/2017 04:00|24/11/2017 04:00|             115|           0.4|                 0|                  0|\n|      9|  3981|13/11/2017 10:00|13/11/2017 10:00|              14|           0.1|                 0|                  0|\n|      5|  3970|12/11/2017 03:00|12/11/2017 03:00|             475|           1.6|                 0|                  0|\n|      7|  4628|01/11/2017 10:00|01/11/2017 10:00|             238|           0.7|                 0|                  0|\n|     20|  3953|11/11/2017 10:00|11/11/2017 10:00|             235|           0.7|                 0|                  0|\n|     13|   109|28/11/2017 23:00|28/11/2017 23:00|               0|           0.0|                 0|                  0|\n|      8|  3981|16/11/2017 13:00|16/11/2017 13:00|               6|           0.0|                 0|                  0|\n|     18|  4640|29/11/2017 11:00|29/11/2017 11:00|               1|           0.0|                 0|                  0|\n|      2|  1514|18/11/2017 21:00|18/11/2017 21:00|             671|          0.65|                 0|                  0|\n|     12|  4643|21/11/2017 13:00|21/11/2017 13:00|               6|           0.1|                 0|                  0|\n|     21|  3967|01/11/2017 18:00|01/11/2017 18:00|             139|           0.2|                 0|                  0|\n|      1|  1514|07/11/2017 21:00|07/11/2017 21:00|              81|          0.04|                 0|                  0|\n|     17|  4640|29/11/2017 11:00|29/11/2017 11:00|             269|           0.9|                 0|                  0|\n|     16|  3999|15/11/2017 21:00|15/11/2017 21:00|              63|           0.3|                 0|                  0|\n|     11|  4643|21/11/2017 13:00|21/11/2017 13:00|               1|           0.0|                 0|                  0|\n+-------+------+----------------+----------------+----------------+--------------+------------------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a090c311-703b-4541-95a2-99610521d668",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro2 = spark.sql(\"\"\"\n",
    "        select *\n",
    "        from \n",
    "            (select company_name, count(trip_id) as trips_amount \n",
    "            from cabs inner join trips on cabs.cab_id=trips.cab_id\n",
    "        where company_name like '%Yellow%'  and start_ts::date between '2017-11-01' and '2017-11-07'\n",
    "            group by cabs.company_name) as sub1 union\n",
    "            (select company_name, count(trip_id) as trips_amount\n",
    "        from cabs inner join trips on cabs.cab_id=trips.cab_id\n",
    "        where company_name like '%Blue%'  and start_ts::date between '2017-11-01' and '2017-11-07'\n",
    "            group by cabs.company_name) \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea1d88f4-da3d-45a5-992e-b7c887b617ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro3 = spark.sql(\"\"\"\n",
    "                    select\n",
    "                        CASE\n",
    "                        WHEN company_name ='Flash Cab' THEN  company_name\n",
    "                        WHEN company_name = 'Taxi Affiliation Services' THEN  company_name\n",
    "                        ELSE 'Other' END AS company,\n",
    "                        count(trips.trip_id) as trips_amount\n",
    "                        \n",
    "                    FROM\n",
    "                        cabs inner join trips on cabs.cab_id=trips.cab_id\n",
    "                    WHERE \n",
    "                        trips.start_ts::date BETWEEN '2017-11-01' AND '2017-11-07'\n",
    "                    group by company\n",
    "                    ORDER BY \n",
    "                        trips_amount DESC;\n",
    "                    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7c74f7c-2c12-417a-bdbb-4ca13bc02396",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro4= spark.sql(\"\"\"\n",
    "                select neighborhood_id, name from neighborhoods \n",
    "                where name in ('O''Hare','Loop');\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a8e6ab-41f2-4c5e-a7a7-f7076e8e5cf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro5=spark.sql(\"\"\"\n",
    "                  select ts, \n",
    "                    case WHEN description LIKE '%rain%' OR description LIKE '%storm%' THEN  'Bad'\n",
    "                    else 'Good' end as weather_conditions\n",
    "                from weather_records\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd287be7-c64d-4e96-b4d6-55042287d44a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro6=spark.sql(\"\"\"\n",
    "                  select start_ts, \n",
    "                    case WHEN description LIKE '%rain%' OR description LIKE '%storm%' THEN  'Bad'\n",
    "                    else 'Good' end as weather_conditions,\n",
    "                    duration_seconds\n",
    "                from trips join weather_records on trips.start_ts=weather_records.ts\n",
    "                where pickup_location_id=50 and dropoff_location_id=63 and EXTRACT (DOW from trips.start_ts) = 6\n",
    "                order by trip_id\n",
    "                \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d45237e3-b5d1-410a-917a-c56e232fce9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+----------------+\n|start_ts|weather_conditions|duration_seconds|\n+--------+------------------+----------------+\n+--------+------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "filtro6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a268c4a-7c4f-4be9-9837-04928ac9d026",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtro1.write.mode(\"overwrite\").parquet(\"/mnt/container1/sql_result_01\")\n",
    "filtro2.write.mode(\"overwrite\").parquet(\"/mnt/container1/sql_result_02\")\n",
    "filtro3.write.mode(\"overwrite\").parquet(\"/mnt/container1/sql_result_03\")\n",
    "filtro4.write.mode(\"overwrite\").parquet(\"/mnt/container1/sql_result_04\")\n",
    "filtro5.write.mode(\"overwrite\").parquet(\"/mnt/container1/sql_result_05\")\n",
    "filtro6.write.mode(\"overwrite\").parquet(\"/mnt/container1/sql_result_06\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Factores externos en tiempo de viajes.",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
